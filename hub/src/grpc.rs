use std::sync::Arc;
use std::time::Duration;

use bytes::Bytes;
use tokio::sync::mpsc;
use tokio_util::sync::CancellationToken;
use tonic::transport::Channel;
use tonic::Streaming;
use tracing::{error, info, warn};

use crate::audio::{AudioBus, AudioFrame, TtsFrame};

// Generated by tonic-build from proto/naila.proto.
// build.rs: tonic_build::compile_protos("proto/naila.proto")?;
pub mod proto {
    tonic::include_proto!("naila");
}

use proto::naila_ai_client::NailaAiClient;
use proto::{AudioCodec, AudioInput, AudioOutput, SpeechEvent};

// ─────────────────────────────────────────────────────────────────────────────
// Config
// ─────────────────────────────────────────────────────────────────────────────

pub struct GrpcConfig {
    /// AI server address (e.g., "http://192.168.1.100:50051").
    pub server_addr: String,
    /// Initial delay before first reconnection attempt.
    pub initial_backoff: Duration,
    /// Maximum delay between reconnection attempts.
    pub max_backoff: Duration,
}

impl Default for GrpcConfig {
    fn default() -> Self {
        Self {
            server_addr: "http://127.0.0.1:50051".to_owned(),
            initial_backoff: Duration::from_secs(1),
            max_backoff: Duration::from_secs(30),
        }
    }
}

// ─────────────────────────────────────────────────────────────────────────────
// Public entry point
// ─────────────────────────────────────────────────────────────────────────────

/// Runs the gRPC client loop. Connects to the AI server, streams audio
/// from the AudioBus, and routes TTS responses back to devices.
///
/// Reconnects with exponential backoff on failure. Drops queued audio
/// while disconnected — stale frames are useless.
///
/// Runs until the CancellationToken is cancelled.
pub async fn run_grpc_client(
    config: GrpcConfig,
    audio_bus: Arc<AudioBus>,
    mut audio_rx: mpsc::Receiver<(String, AudioFrame)>,
    cancel: CancellationToken,
) {
    let mut backoff = config.initial_backoff;

    loop {
        if cancel.is_cancelled() {
            info!("gRPC client shutting down");
            return;
        }

        info!(addr = %config.server_addr, "connecting to AI server");

        match connect_and_stream(&config, &audio_bus, &mut audio_rx, &cancel).await {
            Ok(()) => {
                info!("gRPC stream ended cleanly");
                return;
            }
            Err(e) => {
                error!("gRPC stream failed: {e}");
                drain_stale(&mut audio_rx);

                warn!(delay_ms = backoff.as_millis(), "reconnecting after backoff");
                tokio::select! {
                    _ = tokio::time::sleep(backoff) => {}
                    _ = cancel.cancelled() => return,
                }

                backoff = (backoff * 2).min(config.max_backoff);
            }
        }
    }
}

// ─────────────────────────────────────────────────────────────────────────────
// Session
// ─────────────────────────────────────────────────────────────────────────────

/// One gRPC session. Opens a bidirectional stream and runs send/recv
/// concurrently until either side fails or cancellation fires.
async fn connect_and_stream(
    config: &GrpcConfig,
    audio_bus: &Arc<AudioBus>,
    audio_rx: &mut mpsc::Receiver<(String, AudioFrame)>,
    cancel: &CancellationToken,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    let channel = Channel::from_shared(config.server_addr.clone())?
        .connect()
        .await?;

    let mut client = NailaAiClient::new(channel);

    info!("gRPC channel connected, opening stream");

    // Tonic takes ownership of the request stream at call time, so we
    // can't hand audio_rx directly — it needs to survive reconnects.
    // Per-session channel: send loop copies from audio_rx into this,
    // tonic owns the receiver side.
    let (session_tx, session_rx) = mpsc::channel::<AudioInput>(128);
    let outbound_stream = tokio_stream::wrappers::ReceiverStream::new(session_rx);

    let response = client.stream_conversation(outbound_stream).await?;
    let inbound = response.into_inner();

    info!("bidirectional stream established");

    let send_fut = send_loop(audio_rx, session_tx, cancel);
    let recv_fut = recv_loop(inbound, audio_bus, cancel);

    tokio::select! {
        r = send_fut => r,
        r = recv_fut => r,
        _ = cancel.cancelled() => Ok(()),
    }
}

// ─────────────────────────────────────────────────────────────────────────────
// Send loop: AudioBus → gRPC outbound
// ─────────────────────────────────────────────────────────────────────────────

/// Reads (device_id, AudioFrame) tuples from the bus, wraps them in
/// AudioInput protobufs, and pushes into the session stream.
async fn send_loop(
    audio_rx: &mut mpsc::Receiver<(String, AudioFrame)>,
    session_tx: mpsc::Sender<AudioInput>,
    cancel: &CancellationToken,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    let mut sequence: u32 = 0;

    loop {
        tokio::select! {
            item = audio_rx.recv() => {
                let (device_id, frame) = match item {
                    Some(pair) => pair,
                    None => {
                        info!("audio bus closed, ending send loop");
                        return Ok(());
                    }
                };

                let msg = AudioInput {
                    device_id,
                    // DEFERRED: room_id and conversation_id are empty.
                    // AI server tracks conversations by device_id alone.
                    // When multi-room support is needed, the command center
                    // will need a registry mapping device_id → (room, conversation).
                    room_id: String::new(),
                    conversation_id: String::new(),
                    audio: Some(proto::audio_input::Audio::AudioPcm(
                        frame.data.to_vec(),
                    )),
                    codec: AudioCodec::PcmS16le as i32,
                    sample_rate: frame.sample_rate,
                    chunk_duration_ms: 20,
                    timestamp_ms: frame.timestamp,
                    sequence_num: sequence,
                    // DEFERRED: event is always Continue. Once VAD is
                    // integrated in run_device, it should tag frames with
                    // Start/Continue/End. This will require the bus to
                    // carry a SpeechEvent alongside the audio.
                    event: SpeechEvent::Continue as i32,
                };

                sequence = sequence.wrapping_add(1);

                if session_tx.send(msg).await.is_err() {
                    return Err("outbound stream closed".into());
                }
            }
            _ = cancel.cancelled() => return Ok(()),
        }
    }
}

// ─────────────────────────────────────────────────────────────────────────────
// Recv loop: gRPC inbound → route to device
// ─────────────────────────────────────────────────────────────────────────────

/// Receives AudioOutput messages from the AI server and routes TTS audio
/// to the correct device via AudioBus.tts_sub.
async fn recv_loop(
    mut inbound: Streaming<AudioOutput>,
    audio_bus: &Arc<AudioBus>,
    cancel: &CancellationToken,
) -> Result<(), Box<dyn std::error::Error + Send + Sync>> {
    loop {
        tokio::select! {
            msg = inbound.message() => {
                let msg = match msg? {
                    Some(m) => m,
                    None => {
                        info!("AI server closed the stream");
                        return Ok(());
                    }
                };

                if msg.error_code != proto::ErrorCode::ErrorNone as i32 {
                    warn!(
                        device_id = %msg.device_id,
                        code = msg.error_code,
                        error = %msg.error_message,
                        "AI server reported error"
                    );
                    continue;
                }

                if msg.audio_pcm.is_empty() {
                    continue;
                }

                let tts_frame = TtsFrame {
                    data: Bytes::from(msg.audio_pcm),
                    sample_rate: msg.sample_rate,
                };

                if let Some(tx) = audio_bus.tts_sub.get(&msg.device_id) {
                    if tx.send(tts_frame).await.is_err() {
                        warn!(
                            device_id = %msg.device_id,
                            "device TTS channel closed, dropping frame"
                        );
                    }
                } else {
                    warn!(
                        device_id = %msg.device_id,
                        "no device subscribed for TTS, dropping frame"
                    );
                }
            }
            _ = cancel.cancelled() => return Ok(()),
        }
    }
}

// ─────────────────────────────────────────────────────────────────────────────
// Helpers
// ─────────────────────────────────────────────────────────────────────────────

/// Drain all pending frames after a disconnect so we don't send stale
/// audio on reconnect.
fn drain_stale(rx: &mut mpsc::Receiver<(String, AudioFrame)>) {
    let mut dropped = 0u64;
    while rx.try_recv().is_ok() {
        dropped += 1;
    }
    if dropped > 0 {
        warn!(count = dropped, "drained stale audio frames");
    }
}
